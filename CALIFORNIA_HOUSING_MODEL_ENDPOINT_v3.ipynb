{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "lastEditStatus": {
   "notebookId": "rnxvjg7svc6g5ebasvpr",
   "authorId": "5701463825645",
   "authorName": "VINOTHTRUE",
   "authorEmail": "vinothtrue@gmail.com",
   "sessionId": "fff58b1a-f43d-4eba-ad54-b7f2fb99e819",
   "lastEditTime": 1757755421238
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c1d6b5-58f2-4fbd-be8c-35643c516e0e",
   "metadata": {
    "name": "Model_Inferencing_Endpoint"
   },
   "source": [
    "# California Housing Model Inferencing Endpoint\n",
    "This notebook walks through creating a simple machine learning model using the California Housing dataset, registering it with \n",
    "the Model Registry, and creating a publicly accessible model inferencing endpoint. It then\n",
    "demonstrates how to get programmatic access to the model inferencing endpoint from outside\n",
    "of Snowflake using a Programmatic Access Token (PAT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d29d7c-0aed-4ab7-a234-1fdf5b9a8325",
   "metadata": {
    "name": "Setup_Snowflake"
   },
   "source": [
    "## 1. Setup Snowflake\n",
    "Before we proceed, go to the Packages\" pull-down and enter `scikit-learn` in the \"Find Packages\" textbox and select `scikit-learn`. Do the same with `snowflake-ml-python`. Lastly, do the same with `numpy` and make sure to choose the latest version _before_ 2.0 (e.g., `1.26.4`). Then click \"Save\", which will also restart the Notebook.\n",
    "\n",
    "First we create a database, schema, and role for use in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "outputs": [],
   "source": "USE ROLE accountadmin;\nCREATE ROLE IF NOT EXISTS ml_role;\nGRANT ROLE ml_role TO ROLE ACCOUNTADMIN;\nCREATE DATABASE IF NOT EXISTS api;\nCREATE SCHEMA IF NOT EXISTS api.ml;\nGRANT ALL ON DATABASE api TO ROLE ml_role;\nGRANT ALL ON SCHEMA api.ml TO ROLE ml_role;"
  },
  {
   "cell_type": "markdown",
   "id": "89689e76-9c9b-4559-a5fa-ad59a0d4709e",
   "metadata": {
    "name": "cell14"
   },
   "source": [
    "Next, let's create a compute pool for our service, and grant usage permissions to our `ML_ROLE` role. \n",
    "We also grant the `ML_ROLE` role the permission to create services with public endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "USE ROLE accountadmin;\n",
    "CREATE COMPUTE POOL IF NOT EXISTS pool_api \n",
    " MIN_NODES = 1\n",
    " MAX_NODES = 1\n",
    " INSTANCE_FAMILY = CPU_X64_XS;\n",
    "GRANT ALL ON COMPUTE POOL pool_api TO ROLE ml_role;\n",
    "GRANT BIND SERVICE ENDPOINT ON ACCOUNT TO ROLE ml_role;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ea29d-1917-416c-a9ee-76349c67385f",
   "metadata": {
    "name": "cell16"
   },
   "source": [
    "Since we are going to be using Snowpark Container Services to host the inferencing endpoint, we\n",
    "will need an `IMAGE REPOSITORY` to store the model image. We create that using the `ML_ROLE` role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab3b8ef-36cc-4297-9266-9a96f3bfe8ef",
   "metadata": {
    "language": "sql",
    "name": "cell23"
   },
   "outputs": [],
   "source": [
    "USE ROLE ml_role;\n",
    "CREATE IMAGE REPOSITORY IF NOT EXISTS api.ml.repo_ml;"
   ]
  },
  {
   "cell_type": "code",
   "id": "7ad1edd6-1a35-4d27-acb2-5dee6d575526",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5c102ae5-3e15-4f49-83f6-857dcc84b190",
   "metadata": {
    "name": "Create_the_Model"
   },
   "source": [
    "## 2. Create the Model\n",
    "\n",
    "Now we turn our attention to the actual machine learning model. \n",
    "\n",
    "For illustrative purposes, we are creating a multiple linear regression model based on the California Housing\n",
    "dataset included in Scikit Learn. This dataset contains information collected from the 1990 California census\n",
    "and is used to predict median house values in California districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c436c-d669-43c1-be60-3106495c1930",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "import numpy as np\nfrom sklearn import datasets, linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom snowflake.snowpark import Session\n\nimport sklearn \nimport numpy as np\n\n# Assume you have an active Snowpark session\nsession = get_active_session()\n\n# Query the table\ndf_snowflake = session.table(\"CALIFORNIA_HOUSING_RAW\")\n\n# Convert to Pandas DataFrame\npandas_df = df_snowflake.to_pandas()\n\n# Display first few rows\nprint(pandas_df.head())\n\n\n\n# Assuming pandas_df is your full DataFrame loaded from Snowflake\nhousing_X = pandas_df.drop(columns=['MEDHOUSEVALUE'])\nhousing_y = pandas_df['MEDHOUSEVALUE']\n\n# Optional: Display shapes to verify\nprint(f\"Features shape: {housing_X.shape}\")\nprint(f\"Target shape: {housing_y.shape}\")\n\n\n#train test split\nhousing_X_train, housing_X_test, housing_y_train, housing_y_test = train_test_split(\n    housing_X, housing_y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nhousing_X_train_scaled = scaler.fit_transform(housing_X_train)\nhousing_X_test_scaled = scaler.transform(housing_X_test)\n\n# Scale the features for better model performance\n\n\n# Create linear regression object\nregr = linear_model.LinearRegression()\n\n# Train the model using the training sets\nregr.fit(housing_X_train_scaled, housing_y_train)\n\n# Print model performance\ntrain_score = regr.score(housing_X_train_scaled, housing_y_train)\ntest_score = regr.score(housing_X_test_scaled, housing_y_test)\nprint(f\"\\nModel Performance:\")\nprint(f\"Training R² Score: {train_score:.4f}\")\nprint(f\"Testing R² Score: {test_score:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "a187477f-dfcf-403d-a437-6f56cdb3ce37",
   "metadata": {
    "name": "cell18"
   },
   "source": [
    "Now that we have created our `regr` linear regression model, let's test it by calling the `predict()` function directly with some sample data from our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0604c9-a496-4889-b2ad-fdc13e10984d",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "# Test the model with first 3 samples from test set\nsample_predictions = regr.predict(housing_X_test_scaled[:3])\n\nactual_values = housing_y_test[:3]\nprint(sample_predictions)\nprint(actual_values)"
  },
  {
   "cell_type": "markdown",
   "id": "c0f3410c-9168-46c5-a136-240b7d0c31e1",
   "metadata": {
    "name": "Register_the_Model"
   },
   "source": [
    "## 3. Register the Model\n",
    "\n",
    "Now we can turn our attention to registering our Scikit Learn model in the Snowflake Model Registry.\n",
    "\n",
    "First, we create a Snowpark Session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6356d653-9c93-40d0-b710-3c7fddb50427",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b366e585-e1c1-4256-9699-0ed4a956a96b",
   "metadata": {
    "name": "cell20"
   },
   "source": [
    "Next, we create a Snowflake ML Registry object using the Snowpark Session. We provide the database, `API`, and the schema `ML`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23cb54-c421-4c0b-bc42-58e5417a3a62",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "session.use_schema('API.ML')\n",
    "session.use_role('ML_ROLE')\n",
    "reg = Registry(session=session, database_name=\"API\", schema_name=\"ML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f1e90-44fd-4f0f-a738-6a68d42fe8f4",
   "metadata": {
    "name": "cell21"
   },
   "source": [
    "Next, we register the `regr` model with the Model Registry. We provide a name for the model (`linreg_housing`), a version name (`v1`), and an optional comment. We need to list the Anaconda dependencies for this model. We also provide some sample input data so that the schema of the data can be inferred. Lastly, we provide some options to limit warnings.\n",
    "\n",
    "We then show the models in the Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6162d40e-c290-4589-b8a1-57416a579460",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "# Note: We need to create a model that includes the scaler as well\n",
    "# For simplicity, we'll create a pipeline that includes both scaling and regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with scaling and regression\n",
    "housing_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', linear_model.LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the original (unscaled) training data\n",
    "housing_pipeline.fit(housing_X_train, housing_y_train)\n",
    "\n",
    "# Register the pipeline model\n",
    "mv = reg.log_model(housing_pipeline,\n",
    "                   model_name=\"linreg_housing\",\n",
    "                   version_name=\"v1\",\n",
    "                   conda_dependencies=[\"scikit-learn\", \"numpy\"],\n",
    "                   comment=\"California Housing Linear Regression with Scaling\",\n",
    "                   options={\"relax_version\": True},\n",
    "                   sample_input_data=housing_X_test[:10])\n",
    "\n",
    "reg.show_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd17344-4408-4703-bf31-0554c0e181c1",
   "metadata": {
    "name": "cell22"
   },
   "source": [
    "Now that we have the model registered, we will create a `SERVICE` in Snowpark Container Services (SPCS) to host the inferencing endpoint. We provide a service name (`linreg_housing_svc`), a compute pool to use (`pool_api`, which we created earlier), and an image repository to hold the image (`repo_ml`, which we created earlier). Lastly, we indicate that the service should expose the model inferencing endpoint publicly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64aea16-a994-48bf-af76-438f328ff23c",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "# Deploy the model to SPCS\n",
    "mv.create_service(\n",
    "    service_name=\"linreg_housing_svc\",\n",
    "    service_compute_pool=\"pool_api\",\n",
    "    image_repo=\"API.ML.REPO_ML\",\n",
    "    ingress_enabled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce397dc-1676-4ea4-881a-7d94146a87d5",
   "metadata": {
    "name": "Accessing_the_Model_Inferencing_Endpoint"
   },
   "source": [
    "## Accessing the Model Inferencing Endpoint\n",
    "\n",
    "We want to set up a separate user and role to access the model inferencing endpoint, as opposed to using the role that created the service.\n",
    "\n",
    "First, we create a new `ML_SCORING_ROLE` role and grant it access to the `API` database and `ML` schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08cab7-710f-47a6-ae18-2629cd6d4d11",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "USE ROLE ACCOUNTADMIN;\n",
    "CREATE ROLE IF NOT EXISTS ml_scoring_role;\n",
    "GRANT ROLE ml_scoring_role TO ROLE accountadmin;\n",
    "GRANT USAGE ON DATABASE api TO ROLE ml_scoring_role;\n",
    "GRANT USAGE ON SCHEMA api.ml TO ROLE ml_scoring_role;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d49998-622d-4207-a6a9-83dc3b329d96",
   "metadata": {
    "name": "cell26"
   },
   "source": [
    "Next, we create a user that we can use externally to access the endpoint. This user (`ML_SCORING_USER`) is granted the `ML_SCORING_ROLE` role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a50cb9-41b5-4160-b2be-b129034ea32f",
   "metadata": {
    "language": "sql",
    "name": "cell11"
   },
   "outputs": [],
   "source": [
    "USE ROLE ACCOUNTADMIN;\n",
    "CREATE USER IF NOT EXISTS ml_scoring_user PASSWORD='User123' DEFAULT_ROLE = ml_scoring_role\n",
    " DEFAULT_SECONDARY_ROLES = ('ALL') MUST_CHANGE_PASSWORD = FALSE;\n",
    "GRANT ROLE ml_scoring_role TO USER ml_scoring_user;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a812f54c-55b4-4d17-ae8c-85db1bda5b73",
   "metadata": {
    "name": "cell27"
   },
   "source": [
    "Next, we create a Programmatic Access Token (PAT) that we can use to programmatically access the model inferencing endpoint from outside of Snowflake. \n",
    "\n",
    "In order to create a PAT, the user must have a network policy, so we create a network policy that allows access from any source IP address. In practice, this network policy should be set as narrowly as possible. Then, we assign that network policy to our user.\n",
    "\n",
    "Then, we create a PAT for the `ML_SCORING_USER` user. We will need this token to access from outside Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e12bd2-ed30-44c7-ab84-94e906670e37",
   "metadata": {
    "language": "sql",
    "name": "cell12"
   },
   "outputs": [],
   "source": "USE ROLE ACCOUNTADMIN;\nCREATE NETWORK POLICY IF NOT EXISTS api_np ALLOWED_IP_LIST = ('0.0.0.0/0');\nALTER USER ml_scoring_user SET NETWORK_POLICY = api_np;\nALTER USER IF EXISTS ml_scoring_user ADD PROGRAMMATIC ACCESS TOKEN ml_scoring_token_house;"
  },
  {
   "cell_type": "markdown",
   "id": "c6dd1b72-3ee5-4f04-b3d2-43d67eb26263",
   "metadata": {
    "name": "cell28"
   },
   "source": [
    "We now grant access to the public endpoint to the `ML_SCORING_ROLE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f29e51-6314-4a30-93c5-a7051484087c",
   "metadata": {
    "language": "sql",
    "name": "cell24"
   },
   "outputs": [],
   "source": [
    "GRANT SERVICE ROLE api.ml.linreg_housing_svc!all_endpoints_usage TO ROLE ml_scoring_role;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38090062-d4b0-4dea-b9d7-4005986b9f2f",
   "metadata": {
    "name": "cell29"
   },
   "source": [
    "Lastly, we need the actual hostname for the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ccf59a-e874-445b-b6f0-95074ea13d37",
   "metadata": {
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "SHOW ENDPOINTS IN SERVICE api.ml.linreg_housing_svc;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1288798-3ccc-48f7-ae64-19074f9dc3d8",
   "metadata": {
    "name": "test_endpoint"
   },
   "source": [
    "## Test the Endpoint\n",
    "\n",
    "Let's test our deployed model by making a prediction on some sample data from our test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a5e5a-a75a-4f51-8fd9-a6f9e2ba29bc",
   "metadata": {
    "name": "Example"
   },
   "source": [
    "## Example\n",
    "\n",
    "Now we show an example of using the Python classes programmatically so you can incorporate it into your code.\n",
    "\n",
    "Run the following cell to see the code you can use to access the endpoint programmatically in Python. It uses output from previous cells and some SQL to get the values needed in the sample code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a4366-923d-4c8e-89c4-3f6e6170456c",
   "metadata": {
    "codeCollapsed": true,
    "language": "python",
    "name": "cell31"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "pat = cell12.to_pandas().iloc[0].to_dict()['token_secret']\n",
    "scoring_endpoint = f\"https://{cell13.to_pandas().iloc[0].to_dict()['ingress_url']}/predict\"\n",
    "\n",
    "# Get sample data for the example\n",
    "sample_data = housing_X_test[0].tolist()  # First test sample\n",
    "sample_json = json.dumps({\"data\": [[0] + sample_data]}, indent=2)\n",
    "\n",
    "st.markdown(f\"\"\"\n",
    "```python\n",
    "import requests\n",
    "import json\n",
    "pat = \"{pat}\"\n",
    "scoring_endpoint = \"{scoring_endpoint}\"\n",
    "\n",
    "# Set up the headers to use\n",
    "headers = {{'Authorization': f'Snowflake Token=\"{pat}\"'}}\n",
    "\n",
    "# Sample California Housing data (8 features):\n",
    "# [MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude]\n",
    "sample_payload = {sample_json}\n",
    "\n",
    "# Each call to the endpoint looks like this:\n",
    "resp = requests.post(url=scoring_endpoint, \n",
    "                     headers=headers, \n",
    "                     json=sample_payload)\n",
    "\n",
    "# Do something with the scores (house price predictions)\n",
    "scores = resp.json()\n",
    "print(f\"Predicted house price: ${{scores['data'][0][1]['output_feature_0']:.2f}}00k\")\n",
    "```\n",
    "\"\"\")\n",
    "\n",
    "st.markdown(\"### California Housing Dataset Features:\")\n",
    "st.markdown(\"\"\"\n",
    "- **MedInc**: median income in block group\n",
    "- **HouseAge**: median house age in block group\n",
    "- **AveRooms**: average number of rooms per household\n",
    "- **AveBedrms**: average number of bedrooms per household\n",
    "- **Population**: block group population\n",
    "- **AveOccup**: average number of household members\n",
    "- **Latitude**: block group latitude\n",
    "- **Longitude**: block group longitude\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23de06-e61b-4c14-bac4-96668086174e",
   "metadata": {
    "name": "Cleanup"
   },
   "source": [
    "## Cleanup\n",
    "If you are finished with this example, we can now delete the scoring service, the model, the user and scoring role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479299c-0eb2-43cd-bf0e-b7e16eb3269d",
   "metadata": {
    "language": "sql",
    "name": "cell33"
   },
   "outputs": [],
   "source": [
    "USE ROLE accountadmin;\n",
    "ALTER SERVICE api.ml.linreg_housing_svc SUSPEND;\n",
    "DROP SERVICE api.ml.linreg_housing_svc;\n",
    "DROP USER ml_scoring_user;\n",
    "DROP ROLE ml_scoring_role;\n",
    "DROP MODEL api.ml.linreg_housing;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8998bb7-04ce-40cb-aeb9-de46fa2ca1d7",
   "metadata": {
    "name": "cell35"
   },
   "source": [
    "You can drop the following resources, as well, but if those are being used for other purposes (e.g., you have other things using the compute pool we created), comment out (or delete) those lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb34473-1adc-4574-9829-b2bbed499a8f",
   "metadata": {
    "language": "sql",
    "name": "cell34"
   },
   "outputs": [],
   "source": [
    "USE ROLE accountadmin;\n",
    "DROP IMAGE REPOSITORY api.ml.repo_ml;\n",
    "DROP COMPUTE POOL pool_api;\n",
    "DROP ROLE ml_role;\n",
    "DROP SCHEMA api.ml;"
   ]
  }
 ]
}